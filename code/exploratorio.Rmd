---
title: "Tesis LMA"
author: "Mario Becerra 124362"
date: "Julio 2016"
output: html_document
---

```{r setup, message=FALSE}
library(dplyr)
library(tidyr)
library(Matrix)
library(ggplot2)
```

## Recomendación

Utilizaremos datos de movielens para construir un sistema de recomendación de películas a usuarios. 

Cargamos y analizamos los datos.

```{r}
calis <- readr::read_csv('../data/ml-20m/ratings.csv') %>% 
  rename(itemId_orig = movieId) %>% 
  mutate(itemId = as.integer(factor(itemId_orig))) %>% 
  select(-timestamp)
head(calis)

# con <- file("../data/ml-20m/movies.csv", "r", blocking = FALSE)
# lineas <- readLines(con)
# close(con)
# lista.movies <- list()
# salida <- lapply(lineas, function(linea){
#   sp <- strsplit(linea, '::', fixed=T)[[1]]
#   data_frame(itemId = sp[1], movie_nom = sp[2], tipo = sp[3])
# })

cant_usuarios <- length(unique(calis$userId))
cant_pelis <- length(unique(calis$itemId))
```

Tenemos `r cant_usuarios` distintos usuarios y `r cant_pelis` películas distintas calificadas. Procedemos a crear un conjunto de prueba y uno de entrenamiento.

```{r}
set.seed(2805)

valida_usuarios <- sample(unique(calis$userId), cant_usuarios*.3 )
valida_items <- sample(unique(calis$itemId), cant_pelis*.3 )

dat_2 <- calis %>%
  mutate(valida_usu = userId %in% valida_usuarios) %>%
  mutate(valida_item = itemId %in% valida_items)

dat_train <- dat_2 %>% 
  filter(!valida_usu | !valida_item) %>% 
  select(-valida_usu, -valida_item)

dat_test <- dat_2 %>% 
  filter(valida_usu & valida_item) %>% 
  select(-valida_usu, -valida_item)

head(dat_train)
head(dat_test)

# rm(calis)
rm(dat_2)

cant_usuarios_train <- length(unique(dat_train$userId))
cant_pelis_train <- length(unique(dat_train$itemId))
cant_usuarios_test <- length(unique(dat_test$userId))
cant_pelis_test <- length(unique(dat_test$itemId))
```

El conjunto de entrenamiento cuenta con `r cant_usuarios_train` usuarios y `r cant_pelis_train` películas; mientras que el de validación tiene `r cant_usuarios_test` usuarios y `r cant_pelis_test` películas. 

Creamos ahora un modelo base de referencia. Este modelo es útil para hacer *benchmarking* de intentos de predicción, como primera pieza para construcción de modelos más complejos, y también como una manera simple de producir estimaciones cuando no hay datos suficientes para hacer otro tipo de predicción. Está definido de la siguiente manera:

### {#importante}
Si $x_{ij}$ es el gusto del usuario $i$ por la película $j$, entonces nuestra predicción es
$$\hat{x}_{ij} = \hat{b}_j +  (\hat{a}_i-\hat{\mu} ) $$
donde $a_i$ indica un nivel general de calificaciones del usuario $i$, y $b_j$ es el nivel general de gusto por la película, definidos como

1. Media general
$$\hat{\mu} =\frac{1}{T}\sum_{s,t} x_{st}$$
2. Promedio de calificaciones de usuario $i$ 
$$\hat{a}_i =\frac{1}{M_i}\sum_{t} x_{i,t} $$
3. Promedio de calificaciones de la película $j$ 
$$\hat{b}_j =\frac{1}{N_j}\sum_{s} x_{s,j}$$

También podemos escribir la predicción en términos de desviaciones:

$$\hat{x}_{ij} = \hat{\mu}  +  \hat{c}_i +  \hat{d}_j $$
donde

1. Media general
$$\hat{\mu} =\frac{1}{T}\sum_{s,t} x_{st}$$
2. Desviación de las calificaciones de usuario $i$ respecto a la media general
$$\hat{c}_i =\frac{1}{M_i}\sum_{t} x_{it} - \hat{\mu} $$
3. Desviación  de la película $j$ respecto a la media general
$$\hat{b_j} =\frac{1}{N_j}\sum_{s} x_{sj}- \hat{\mu}.$$

Una vez que observamos una calificación $x_{ij}$, el residual del modelo de referencia es
$$r_{ij} = x_{ij} - \hat{x_{ij}}.$$

```{r, eval=F}
# calc_media_regularizada <- function(df_calis, alpha){
#   # df_calis es un dataframe donde:
#   #   la primera columna tiene los IDs de los usuarios,
#   #   la segunda tiene el ID de la película calificada
#   #   la tercera tiene la calificación
#   # Si tiene más columnas, las elimina
#   df_calis <- df_calis[,1:3]
#   names(df_calis) <- c("userId", "itemId", "rating")
#   mu <- mean(df_calis$rating)
#   medias_usuario <- df_calis %>% 
#     group_by(userId) %>% 
#     summarise(media_usuario = mean(rating),
#               num_calis = n())
#   
#   df_calis <- df_calis %>% 
#     left_join(medias_usuario) %>% 
#     mutate(
#       media_usuario_adj = alpha*mu/(alpha + num_calis) + num_calis*media_usuario/(alpha + num_calis))
#   return(df_calis)
# }
# 
# 
# dat_train_2 <- calc_media_regularizada(dat_train, 10) %>% 
#   # Una columna con el residual del modelo base y
#   # dos columnas extra para tener un identificador de usuario y película
#   mutate(u_id = as.integer(factor(userId)))
# 
# rm(dat_train)

# calc_media_regularizada(dat_train, 10) %>% sample_n(., size = 100000) %>% mutate(num_calis_cat = cut(num_calis, breaks = c(min(num_calis), 15, 30, 60, max(num_calis)))) %>% ggplot() + geom_point(aes(x = rating_centrado, y = rating_centrado_adj, color = num_calis_cat), size = 0.5, alpha = 0.6) + geom_abline(slope = 1, intercept = c(0,0))
# 
# # Obtener la calificación promedio que da cada usuario
# medias_usuario_train <- dat_train %>% 
#   group_by(userId) %>% 
#   summarise(media_usu = mean(rating), num_calif_usu = length(rating))
# 
# # Obtener la calificación promedio obtenida por cada película
# medias_peli_train <- dat_train %>% 
#   group_by(itemId) %>% 
#   summarise(media_peli = mean(rating), num_calif_peli = length(rating))
# 
# # Nuevo dataframe con las calificaciones promedio y la calificación del modelo base
# dat_train_2 <- dat_train %>%
#   left_join(medias_usuario_train) %>%
#   left_join(medias_peli_train) %>%
#   # Una columna con la media general de todas las películas
#   mutate(media_gral = media_gral_train) %>%
#   # Una columna con la calificación ajustada de acuerdo al modelo base
#   mutate(rating_adj = media_usu - media_gral + media_peli) %>% 
#   # Una columna con el residual del modelo base y
#   # dos columnas extra para tener un identificador de usuario y película
#   mutate(res = rating - rating_adj,
#          u_id = as.numeric(factor(userId)),
#          m_id = as.numeric(factor(itemId)))
# 
# rm(dat_train)
# 
# #dat_train_2$res <- dat_train_2$rating - dat_train_2$rating_adj
# # dat_train_2$u_id <- as.numeric(factor(dat_train_2$userId))
# # dat_train_2$m_id <- as.numeric(factor(dat_train_2$itemId))
# medias_peli_train$m_id <- arrange(unique(dat_train_2[,c('itemId','m_id')]), itemId)$m_id
# 
# # Leemos todas las películas y nos quedamos solo con las películas que están en el conjunto de entrenamiento
# pelis <- readr::read_csv('../data/ml-20m/movies.csv') %>% 
#   left_join(unique(select(dat_train_2, itemId, m_id))) %>% 
#   filter(complete.cases(.))
# # pelis <- pelis[complete.cases(pelis),]
# head(dat_train_2)

```




```{r}
# dat_test_2 <- dat_test %>%
#  # left_join(unique(dat_train_2[,c('userId', 'u_id', 'm_id')])) %>%
#   left_join(medias_usuario_train) %>%
#   left_join(medias_peli_train) %>%
#   mutate(media_gral = media_gral_train) %>%
#   mutate(rating_adj = media_usu - media_gral + media_peli)

media_gral_train <- mean(dat_train$rating)

dat_train_2 <-dat_train %>% 
  mutate(u_id = as.integer(factor(userId)),
         rating_cent = rating - media_gral_train)

dat_test_2 <- dat_test %>% 
  left_join(unique(dat_train_2[,c('userId', 'u_id')])) %>% 
  mutate(rating_cent = rating - media_gral_train) %>% 
  filter(!is.na(userId) & !is.na(itemId))

length(unique(dat_test_2$userId))
length(unique(dat_test_2$itemId))
head(dat_test_2)
```

Una forma de mejorar el desempeño en la predicción, es usar dimensiones latentes en los datos. Intuitivamente, esto es que en las similitudes entre usuarios, es razonable pensar que hay ciertos “conceptos” que agrupan o separan películas, y que los usuarios se distinguen por el gusto o no que tienen por estos “conceptos”. Esta idea propone que hay ciertos factores latentes (no observados) que describen películas con “contenido implícito similar”, y usuarios según su interés en esa dimensión.

Las dimensiones latentes que se encuentren pueden tener cierta interpretación como "serio-divertido", o "con violencia-sin violencia", o puede ser que sean totalmente interpretables, pues se obtienen matemáticamente.

Con $k$ dimensiones latentes, el modelo que proponemos es:

$$\tilde{X} = UV^t$$

donde $U$ es una matrix de $nxk$ (n= número de usuarios), y $V$ es una matriz
de $mxk$, donde $m$ es el número de películas.

#### Nota: Escribir bien modelo utilizado

Buscamos que, si $X$ son las verdaderas calificaciones, entonces
$$X\approx \tilde{X}.$$

y nótese que esta aproximación es en el sentido de las entradas de $X$ que **son observadas**. Sin embargo, $\tilde{X}$ nos da predicciones para **todos los pares película-persona**.

Bajo este modelo, la predicción para el usuario $i$ y la película $j$ es la siguiente suma sobre las dimensiones latentes:

$$\tilde{x}_{ij} =\sum_k u_{ik} v_{jk}$$

que expresa el hecho de que el gusto de $i$ por $j$ depende de una combinación (suma) de factores latentes de películas ponderados por gusto por esos factores del usuario.

El número de factores latentes $k$ debe ser seleccionado (por ejemplo, según el error de validación). Dado $k$, para encontrar $U$ y $V$ (un total de $k(m+n)$ parámetros) buscamos
minimizar 

$$\sum_{(i,j)\, obs} (x_{ij}-\tilde{x}_{ij})^2$$.

Además de esto, podemos usar también ideas de nuestro modelo base y modelar desviaciones en lugar de calificaciones directamente. Esto es, si $X^0$ son las predicciones del modelo base de referencia, y 
$$R = X-X^0$$
son los residuales del modelo base, buscamos mejor
$$R\approx \tilde{X} = UV^t.$$
de manera que las predicciones finales son
$$X^0 + \tilde{X}.$$

Y más aún, podemos usar regularización para que en lugar de optimizar la función de arriba, intentamos más bien minimizar (para una solo factor latente)

$$\sum_{(i,j)\, obs} (r_{ij} - u_i v_j)^2  + \lambda \sum_i u_i^2 + \gamma \sum_j v_j^2 $$.

Si queremos _k_ dimensiones latentes, entonces queremos minimizar la función

$$\sum_{(i,j)\, obs} (r_{ij} - \sum_{l=1}^{k}{u_{il} v_{jl}})^2  + \lambda \sum_{i,l} u_{il}^2 + \gamma \sum_{j,l} v_{jl}^2 $$.

Ahora vamos a utilizar descenso en gradiente estocástico para minimizar el error del modelo base y así encontrar los factores latentes en los datos. Primero construimos matrices ralas de usuarios y películas para eficientar el proceso.

```{r}
# i <- dat_train_2$u_id
# j <- dat_train_2$m_id
# y <- dat_train_2$rating_adj
# X <- sparseMatrix(i, j, x = y)

X <- sparseMatrix(i = dat_train_2$u_id,
                  j = dat_train_2$itemId, 
                  x = dat_train_2$rating_cent)
dim(X)

# i.v <- dat_test_2$u_id
# j.v <- dat_test_2$m_id
# y.v <- dat_test_2$rating_adj
# X.v <- sparseMatrix(i.v, j.v, x = y.v, dims=dim(X))
# 
# X.v <- sparseMatrix(i.v, j.v, x = y.v, dims=dim(X))
# 
# dim(X.v)
```

Compilamos las funciones creadas en C++ para acelerar el proceso. Primero se muestra el código para una función que calcula el error de predicción.

```{r}
# Gradiente
readLines('gradiente.cpp') %>% cat(sep = "\n")

# Calcula error
readLines('calc_error_bias.cpp') %>% cat(sep = "\n")
```


```{r}
Rcpp::sourceCpp('gradiente.cpp')
Rcpp::sourceCpp('calc_error_bias.cpp')
```
```{r}
i = dat_train_2$u_id
j = dat_train_2$itemId
y = dat_train_2$rating_cent

i.v = dat_test_2$u_id
j.v = dat_test_2$itemId
y.v = dat_test_2$rating_cent

P <- matrix(rnorm(5*dim(X)[1],0,0.01), ncol=5, nrow=dim(X)[1])
Q <- matrix(rnorm(5*dim(X)[2],0,0.01), ncol=5, nrow=dim(X)[2])
a <- rep(0, dim(X)[1])
b <- rep(0, dim(X)[2])

for(k in 1:30){
  cat("Iteración", k, "\n")
  out <- gradiente(i, 
                   j,
                   y, 
                   P, 
                   Q, 
                   a, 
                   b, 
                   0.004, 
                   0.01)
  P <- out[[1]]
  Q <- out[[2]]
  a <- out[[3]]
  b <- out[[4]]
  cat("Error entrenamiento:", sqrt(calc_error(i, j, y, P, Q, a, b)), "\n")
  cat("Error validación:", sqrt(calc_error(i.v, j.v, y.v, P, Q, a, b)), "\n\n")
}

```

A continuación se puede ver  las películas representadas por el primer y segundo factor latente:

```{r}
items <- read.csv("../data/ml-20m/movies.csv") %>% 
  select(itemId_orig = movieId, title, genres) %>% 
  inner_join(unique(select(calis, itemId_orig, itemId)))
head(items)

Q_df <- data.frame(itemId = 1:dim(Q)[1], Q) %>% 
  left_join(items)


# Factor latente 1:

arrange(Q_df, desc(X1)) %>% head(20) %>% select(X1, title, genres)
arrange(Q_df, desc(X1)) %>% tail(20) %>% select(X1, title, genres)


arrange(Q_df, desc(X2)) %>% head(20) %>% select(X2, title, genres)
arrange(Q_df, desc(X2)) %>% tail(20) %>% select(X2, title, genres)

# num_pelis <- dat_train_2 %>% 
#   group_by(itemId) %>% 
#   summarise(num = length(rating))

# xx <- data.frame(num_pelis %>% arrange(itemId), Q)
```


La siguiente función recibe como parámetros el número de dimensiones latentes (_k_), la $\gamma$ y la $\lambda$ de regularización y las matrices de entrenamiento y validación de usuario-película en formato ralo para que mediante las funciones mostradas anteriormente minimice el error de predicción usando descenso en gradiente estocástico.

```{r, message=FALSE, eval=FALSE}
encontrar_dim_latentes <- function(i, j, y, i.v, j.v, y.v, gamma, lambda, k, deltalim){
  X <- sparseMatrix(i, j, x = y)
  X.v <- sparseMatrix(i.v, j.v, x = y.v, dims=dim(X))
  set.seed(2805)
  P <- matrix(rnorm(k*dim(X)[1],0,0.01), ncol=k, nrow=dim(X)[1])
  Q <- matrix(rnorm(k*dim(X)[2],0,0.01), ncol=k, nrow=dim(X)[2])
  a <- rep(0, dim(X)[1])
  b <- rep(0, dim(X)[2]) 
  l <- 1
  delta <- deltalim+1
  erroresent <- 0
  erroresval <- 0
  while(delta>deltalim & !is.nan(delta) & l<250){
    ee1 <- sqrt(calc_error(i, j, y, P, Q, a, b))
    ev <- sqrt(calc_error(i.v, j.v, y.v, P, Q, a, b))
    erroresent <- append(erroresent,ee1)
    erroresval <- append(erroresval,ev)
    print(l)
    out <- gradiente(i, j, y, P, Q, a, b, gamma, lambda)
    P <- out[[1]]
    Q <- out[[2]]
    a <- out[[3]]
    b <- out[[4]]
    ee2 <- sqrt(calc_error(i, j, y, P, Q, a, b))
    l <- l+1
    delta <- abs(ee2 - ee1)
    print(print(paste('error entrenamiento =',ee2)))
    print(print(paste('error validación =',ev)))
    print(paste('delta =',delta))
  }
  
  df.it <- data.frame(iter=2:l)
  df.it$erroresent <- round(erroresent[2:l], 3)
  df.it$erroresval <- round(erroresval[2:l], 3)
  l<-list(Q,P,df.it)
  names(l) <- c('Q', 'P', 'err')
  l
}
```

Debido a que se tienen que estimar distintos parámetros libres (_k_, $\gamma$ y $\lambda$), probamos distintas combinaciones para ver cuál tiene el menor error de validación.

```{r, eval=FALSE}
dimensiones_lat<- lapply(c(5, 20, 50), function(l) lapply(c(0.002,0.02,0.2), function(m) lapply(c(0.001,0.01,0.1), function(n) {
  print(paste('dim=',l))
  print(paste('gamma=',m))
  print(paste('lambda=',n))
  temp <- encontrar_dim_latentes(i,j,y,i.v,j.v,y.v,m,n,l,0.001) 
  save(temp, file=paste0(paste('./Data/dimlat',l,m,n),'.Rdata') ) 
  rm(temp)} )))
```

Se prueban las matrices $P$ y $Q$ estimadas en el conjunto de validación y se grafican los errores de entrenamiento y validación.

```{r, cache=TRUE, eval=FALSE}
files <- c('./Data/dimlat 20 0.002 0.001.Rdata', './Data/dimlat 20 0.002 0.01.Rdata', './Data/dimlat 20 0.002 0.1.Rdata', './Data/dimlat 20 0.02 0.001.Rdata', './Data/dimlat 20 0.02 0.01.Rdata', './Data/dimlat 20 0.02 0.1.Rdata', './Data/dimlat 20 0.2 0.001.Rdata', './Data/dimlat 20 0.2 0.01.Rdata', './Data/dimlat 20 0.2 0.1.Rdata', './Data/dimlat 50 0.002 0.001.Rdata', './Data/dimlat 50 0.002 0.01.Rdata', './Data/dimlat 50 0.002 0.1.Rdata', './Data/dimlat 5 0.001 0.001.Rdata', './Data/dimlat 5 0.001 0.01.Rdata', './Data/dimlat 5 0.001 0.1.Rdata', './Data/dimlat 5 0.002 0.001.Rdata', './Data/dimlat 50 0.02 0.001.Rdata', './Data/dimlat 5 0.002 0.01.Rdata', './Data/dimlat 50 0.02 0.01.Rdata', './Data/dimlat 5 0.002 0.1.Rdata', './Data/dimlat 50 0.02 0.1.Rdata', './Data/dimlat 5 0.01 0.001.Rdata', './Data/dimlat 5 0.01 0.01.Rdata', './Data/dimlat 5 0.01 0.1.Rdata', './Data/dimlat 5 0.02 0.001.Rdata', './Data/dimlat 50 0.2 0.001.Rdata', './Data/dimlat 5 0.02 0.01.Rdata', './Data/dimlat 50 0.2 0.01.Rdata', './Data/dimlat 5 0.02 0.1.Rdata', './Data/dimlat 50 0.2 0.1.Rdata', './Data/dimlat 5 0.1 0.001.Rdata', './Data/dimlat 5 0.1 0.01.Rdata', './Data/dimlat 5 0.2 0.001.Rdata', './Data/dimlat 5 0.2 0.01.Rdata', './Data/dimlat 5 0.2 0.1.Rdata')

errores <- data.frame()
p <- list()
for(i in 1:length(files)){
  f <- files[i]
  load(f)
  #e <- tail(temp$err,1)
  e <- temp$err[nrow(temp),]
  boolean <- sum(is.nan(temp$Q))>0 | sum(is.nan(temp$P))>0
  if(boolean) {e[2] <- NaN; e[3] <- NaN}
  t <- gsub('?.Rdata', '\\1',gsub('^[^_]*dimlat ', '\\1', f))
  errores <- rbind(errores, cbind(e,file=t))
  df <- gather(temp$err, iter)
  names(df) <- c('iter', 'tipo', 'val')
  if(!boolean) p[[i]] <- ggplot(data=df, aes(x=iter, y=val, colour=tipo)) + geom_point() + geom_path() + ggtitle(t)
}
errores$id <- as.numeric(factor(errores$file))
library(knitr)
kable(arrange(errores, erroresval), format='markdown')
```
```{r, fig.height=40, eval=FALSE}
do.call(marrangeGrob, c(p[!sapply(p, is.null)], ncol=2, heights=10))
```

Podemos notar que hubo ciertos casos de *overflow* numérico, sin embargo, consideramos que fueron pocos y por el momento se desechan estos casos y se trabaja con los que no tuvieron errores numéricos. A continuación se grafican los errores de entrenamiento y validación de cada caso.

```{r, eval=FALSE}
errores_df <- gather(errores[complete.cases(errores),2:4], file)
names(errores_df) <- c('file','tipo_error', 'value')
ggplot(errores_df) + geom_bar(aes(x=file, y=value, fill=tipo_error), position="dodge", stat="identity") +
  theme(axis.text.x = element_text(angle=90, vjust=1)) + 
  geom_hline(yintercept=min(errores$erroresval, na.rm=TRUE)) + 
  geom_hline(yintercept=min(errores$erroresent, na.rm=TRUE))
```

Analicemos algunos usuarios. En particular el usuario usuario 4000 y el usuario 6000, y usuario 1333. Se les recomendarán películas que no hayan visto basado en el modelo de factores latentes.

```{r, message=FALSE, eval=F}
load('./Data/dimlat 50 0.02 0.1.Rdata')

xx <- data.frame(pelis %>% arrange(itemId), temp$Q)

usuario1 <- 4000
usuario2 <- 6000
usuario3 <- 1333

usuarios <- c(4000,6000,1333)

pred_l <- list(); i=1; califs.2 <- list();
for(usuario in usuarios){
  a<-filter(dat_train_2,u_id==usuario)$m_id
  califs.1 <- dat_train_2 %>% filter(u_id==usuario) %>%
    arrange(desc(rating_adj))
  califs.2[[i]] <- left_join(califs.1, pelis)
  pred_l[[i]] <- data.frame(medias_peli_train, pred.x =  temp$Q%*%temp$P[usuario, ] ) %>%
    inner_join(pelis[!(pelis$m_id %in% a),]) %>%
    arrange(desc(pred.x))
  i=i+1
}
```

Para el usuario 4000, la primera tabla contiene las películas que calificó por encima del promedio, es decir, las que más le gustaron, y en la segunda tabla están las recomendaciones que se le dan.

```{r, eval=FALSE}
head(califs.2[[1]],30)[,14:15]
head(pred_l[[1]],20)
```

Para el usuario 6000, las tablas son de la misma forma que para el usuario anterior.

```{r, eval=FALSE}
head(califs.2[[2]],30)[,14:15]
head(pred_l[[2]],20)
```


Para el usuario 1333.

```{r, eval=FALSE}
head(califs.2[[3]],30)[,14:15]
head(pred_l[[3]],20)
```
